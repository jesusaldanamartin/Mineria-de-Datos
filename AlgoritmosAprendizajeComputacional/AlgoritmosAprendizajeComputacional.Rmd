---
title: "Algoritmos de Aprendizaje Computacional"
author: "Jesús Aldana Martín"
date: '2022-05-09'
output: html_document
---

#### Librerias necesarias para la actividad:

```{r dev = 'svg', warning = FALSE}
library(ggplot2)
library(lattice)
library(caret)
library(pROC) # Permite calcular el area bajo la curva.
library(nnet) # Ofrece funciones de R para el Multilayer Perceptron Network.
library(e1071)# Funciones para el algoritmo computacional Support Vector Machine.
library(rpart)# Funciones para el algoritmo computacional Decision Trees.
library(ROCR)
library(plot3D)
library(scatterplot3d)
```

Al igual que para la actividad anterior, debemos de encargarnos de procesar los datos y eliminar aquellos que se hayan perdido, que Rstudio marca como Na.

```{r dev = 'svg', warning = FALSE}

datos <- read.table(file="datos_proporcionados.csv", sep=";", dec=",", header=T, stringsAsFactors = TRUE)
datos$REst[datos$REst == "I"] <- NA
datos$RPro[datos$RPro == "I"] <- NA
datos$Her2[datos$Her2 == "I"] <- NA
datos<- na.omit(datos) 
data <- datos[,-1] #Eliminamos la columna Muestra.

```

#### Función auxiliar :

Función a la que haremos referencia siempre que nos sea necesario calcular el accuracy de un modelo. Esta función crea la matriz de confusión de los datos observados y predichos, para despues hallar la suma de los true positives y false negatives para realizar el cociente por el total de datos y devolvernos un resultado entre 0 y 1.

```{r}
calculo_de_Accuracy <- function(df){
    m_confusion <- table(df$trainPartition, df$predict)
  return (sum(diag(m_confusion))/length(df$predict))
}
```

## Multilayer Perceptron Network

Multilayer artificial neural network es uno de los métodos que mas destacan una vez nos adentramos en los algoritmos de aprendizaje profundo. Un algoritmo ANN de multicapas totalmente conectado suelen incluir 3 capas más una oculta, normalmente el número de capas y el número de neuronas son parámetros variables, por lo que necesitaremos algún método predictivo como Cross-Validation para hallar una solución ideal. Para ajustar el entrenamiento se realiza por retropropagación (Backpropagation).

Por lo general aunque depende de nuestro dataset, a mayor número de redes neuronales mejor procesamiento de datos, sin embargo cuanto más capas mayor sera el error de desvanecimiento del gradiente (vanishing gradient problems). Para ello necesitaremos algoritmos específicos que disminuyan al máximo el error. En caso de tener un accuracy bajo (por debajo e de 0.5) muy posiblimente estemos en un caso de sobreentrenamiento y debamos de ajustar el modelo.

##### FUNCTION nnet --\> #Multilayer Perceptron Network for **TEST**

```{r dev = 'svg', warning = FALSE}

index <- createDataPartition(data$PCR, p=.8, list=FALSE, times=1)
train <- data[index,]
test <- data[-index,]

#Termina o cuando llega al máximo de iteraciones o cuando ya no tiene más senido continuar...
nn.fit <- nnet(train$PCR ~ ., data = train, size=6, entropy=TRUE, maxit=1000, decay=5e-4)

nn.pred_test <- predict(nn.fit, data = test, type="raw")

performance_predict <- ifelse(nn.pred_test > 0.5, 1, 0)


truePositives <- sum(data$PCR[performance_predict==1]==1)
trueNegative <- sum(data$PCR[nn.pred_test==0]==0)
falsePositive <- sum(data$PCR[nn.pred_test==1]==0)
falseNegtive <- sum(data$PCR[nn.pred_test==0]==1)

accu_test <- (truePositives + trueNegative)/(truePositives + trueNegative + falsePositive + falseNegtive) #Accuracy
area_under_curve_test <- auc(train$PCR, nn.pred_test) #AUC
```

##### FUNCTION nnet --\> #Multilayer Perceptron Network for TRAINING

```{r dev = 'svg', warning = FALSE}

nn.fit2 <- nnet(train$PCR ~ ., data = train, size=6, entropy=TRUE, maxit=1000, decay=5e-4)

nn.pred_train <- predict(nn.fit2, data = train, type="raw")

performance_predict2 <- ifelse(nn.pred_train > 0.5, 1, 0)

truePositives2 <- sum(data$PCR[performance_predict2==1]==1)
trueNegative2 <- sum(data$PCR[nn.pred_train==0]==0)
falsePositive2 <- sum(data$PCR[nn.pred_train==1]==0)
falseNegtive2 <- sum(data$PCR[nn.pred_train==0]==1)

accu_train <- (truePositives2 + trueNegative2)/(truePositives2 + trueNegative2 + falsePositive2 + falseNegtive2) #Accuracy
area_under_curve_train <- auc(train$PCR, nn.pred_train) #AUC
```

#### RESULTS

```{r dev = 'svg', warning = FALSE}

accu_test
area_under_curve_test

accu_train
area_under_curve_train
```

## Repeated Multilayer Perceptron Network

La función denominada neuralNetwork_crossVal obtiene como parámetros el dataset de estudio, las veces que se itera el proceso, el número de neuronas y el límite de iteraciones máximo. Al comienzo de la función he creado dos data frames. El primer data frame escribe los accuracy y auc tanto de test como de training, y el segundo data frame muestra las neuronas utilizadas en cada iteración y la media tanto de los accuracys como de las áreas. Inicializo una lista que utilizare para insertar los datos por filas en los dataframes y mediante un bucle while itero tantas veces como pase por parámetro el usuario.


```{r dev = 'svg', warning = FALSE}
neuralNetwork_crossVal <- function(data, k ,NN, decay) {
  
  
    resultados <- data.frame(
      
      accu_train = double(),
      areauc_train = double(),
      accu_test = double(),
      areauc_test = double()
    )
    tabla_resultados <- data.frame(
      Decay = double(),
      NN = double(),
      Accuracy = double(),
      AUC_test = double(),
      AUC_train = double()
    )

    i <- 1
    
    lista <- list()
    lista2 <- list()

    while(k >= i){
      
      index <- createDataPartition(data$PCR, p=.8, list=FALSE, times=1)

      train_df <- data[index,]
      test_df <- data[-index,]
  
      cv_nn.fit <- nnet(PCR == 1 ~ ., data = train_df, size=i, entropy=TRUE, maxit=100000, decay=decay)
    
      cv_nn.pred_train_df <- predict(cv_nn.fit, train_df, type = "raw")

      cv_performance_predict_train <- ifelse(cv_nn.pred_train_df > 0.5, 1, 0)
      trainingSuccesful <- data.frame(trainPartition = train_df$PCR, predict = cv_performance_predict_train)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful))
      lista <-  append(lista,auc(train_df$PCR, cv_nn.pred_train_df))

      # ----- TEST ----- #
      cv_nn.pred_test_df <- predict(cv_nn.fit, test_df, type="raw")

      cv_performance_predict_test <- ifelse(cv_nn.pred_test_df > 0.5, 1, 0)
    
      trainingSuccesful2 <- data.frame(trainPartition = test_df$PCR, predict = cv_performance_predict_test)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful2))
      lista <-  append(lista,auc(test_df$PCR, cv_nn.pred_test_df))

      resultados[nrow(resultados) + 1,] <- lista

      lista2 <- append(lista2, decay)
      lista2 <- append(lista2, i)
      lista2 <- append(lista2, mean(resultados$accu_test))
      lista2 <- append(lista2, mean(resultados$areauc_train))
      lista2 <- append(lista2, mean(resultados$areauc_test))

      tabla_resultados[nrow(tabla_resultados) + 1,] <- lista2

      
      lista <- list()
      lista2 <- list()

      i = i+1
      decay = decay + 0.03
      
    }
   
    print(resultados)
    
    #scatter3D(x=tabla_resultados$NN, y=tabla_resultados$decay, z=tabla_resultados$AUC_test,
      #        bty = "g", pch = 20, cex = 2, ticktype = "detailed", phi = 0)

    #scatterplot3d(tabla_resultados$NN,tabla_resultados$decay,tabla_resultados$AUC_test)

    return(tabla_resultados)
  
}



```

Realizo la llamada a la función anterior :

```{r dev = 'svg', warning = FALSE}

neuralNetwork_crossVal(data, 30 ,11, 0)

```

## Support Vector Machines (SVM)

Las máquinas de soporte de vectores (SVM - Support Vector Machine) es un algoritmo supervisado que puede clasificar los casos mediante la búsqueda de un separador. Las SVM se basan en la idea de encontrar el hiperplano que mejor divida un conjunto de datos en dos clases, esto lo haremos buscando aquellos vectores que tengan la distancia máxima respecto al hiperplano. 

Las dos principales ventajas de las máquinas de vectores de soporte son que son muy buenos en espacios dimensionales grandes y son muy eficientes en el manejo de la memoria. Como desventaja es un algoritmo muy propneso al sobreeentrenamiento por lo que es necesario ajustar sus parámetros adecuadamente. 

```{r dev = 'svg', warning = FALSE}

set.seed(2018)
data$PCR = as.numeric(data$PCR)

index <- createDataPartition(data, p=.7, list=FALSE)
svm_train <- data[index,]
svm_test <- data[-index,]

modelo <- svm(PCR == 1 ~ ., data=data, type = "C-classification", cost =1000, probability=TRUE, gamma =1)
pred <- predict(modelo,data)
#svm.pred <- attr(pred,which="probability")[,"TRUE"]

svm_performance_predict <- ifelse(pred == TRUE, 0, 1)
succesful <- data.frame(trainPartition = data$PCR, predict = svm_performance_predict)

calculo_de_Accuracy(succesful)
auc(data$PCR, as.numeric(pred))

```

```{r dev = 'svg', warning = FALSE}

supportVector_crossVal <- function(data, k, c, g) {
  
     resultados2 <- data.frame(
      cost = double(),
      gamma = double(),
      accu_train = double(),
      areauc_train = double(),
      accu_test = double(),
      areauc_test = double()
    )
    
    i <- 0
    lista <- list()

    while( k>= i){
      
      index <- createDataPartition(data$PCR, p=.7, list=FALSE, times=1)

      train_df <- data[index,]
      test_df <- data[-index,]
      
  
      svm.fit <- svm(PCR ==1 ~ ., data = train_df, cost = c,type = "C-classification" ,gamma = g, probability = TRUE)

      pred <- predict(svm.fit, train_df)
      
      #svm.pred <- attr(pred,which="probabilities")[,"TRUE"]

      svm_performance_predict_train <- ifelse(pred == TRUE, 1, 0)
      trainingSuccesful <- data.frame(trainPartition = train_df$PCR, predict = svm_performance_predict_train)
      lista <- append(lista, c)
      lista <- append(lista, g)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful))
      lista <-  append(lista,auc(train_df$PCR,  as.numeric(pred)))

      # ----- TEST ----- #
      pred2 <- predict(svm.fit, test_df)
      #svm.pred2 <- attr(pred2,which="probabilities")[,"TRUE"]

      svm_performance_predict_test <- ifelse(pred2 == TRUE, 1, 0)
    
      trainingSuccesful2 <- data.frame(trainPartition = test_df$PCR, predict = svm_performance_predict_test)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful2))
      lista <-  append(lista,auc(test_df$PCR,  as.numeric(pred2)))

      resultados2[nrow(resultados2) + 1,] <- lista
      lista <- list()
      i = i+1
      c = c *10
      g = g *10

    }
    
    scatterplot3d(resultados2$cost, resultados2$gamma, resultados2$areauc_test)
    return(resultados2)
  
}

```

Realizo la llamada a la función anterior :

```{r dev = 'svg', warning = FALSE}

supportVector_crossVal(data, 10, 1, 1)

```

## DECISION TREES

Los árboles de decisión son algoritmos de aprendizaje automático supervisado, que tienen la capacidad de realizar tareas de regresión y clasificación. Se caracterizaz según sus nodos o ramas, cada atributo se representa en los nodos y el resultado se representa en las ramas siendo las etiquetas de clase los nodos hoja. Por lo tanto, utiliza un modelo similar a un árbol basado en varias decisiones que se utilizan para calcular sus resultados probables.

```{r}

tree <- rpart(PCR==1 ~ . , data)
result <- predict(tree, data)
result

dt.performance_train <- ifelse(result > 0.5, 1, 0)

trainingSuccesful <- data.frame(trainPartition = data$PCR, predict = dt.performance_train)

calculo_de_Accuracy(trainingSuccesful)
auc(data$PCR, result)


```

Función que calcula mediante el algoritmo de decision tree el accuracy y area para train y test. Se le pasa a la función como parámetros el número de iteraciones y el control(numero entre 0 y 1).
```{r dev = 'svg', warning = FALSE}

decisionTree_crossVal <- function(data, k, cp) {
  
  
    resultados_decisionTrees <- data.frame(
      
      control = double(),
      accu_train = double(),
      areauc_train = double(),
      accu_test = double(),
      areauc_test = double()
    )
    
    i <- 1
    cp <- 0.02
    lista <- list()
    
    while(k >= i){
      


      index <- createDataPartition(data$PCR, p=.8, list=FALSE, times=1)

      tree_train <- data[index,]
      tree_test <- data[-index,]
     
       #TRAIN  
      dt.fit <- rpart(PCR == 1 ~ ., data = tree_train, control = 0.5)
      
      dt.pred_train <- predict(dt.fit, tree_train)
      
      dt.performance_train <- ifelse(dt.pred_train > 0.5, 1, 0)
      trainingSuccesful <- data.frame(trainPartition = tree_train$PCR, predict = dt.performance_train)

      lista <- append(lista, cp)

      lista <-  append(lista,calculo_de_Accuracy(trainingSuccesful))
      lista <-  append(lista,auc(tree_train$PCR, as.numeric(dt.pred_train)))

      # TEST
      #dt.fit2 <- rpart(PCR == 1 ~ ., data = tree_test, control = cp)

      dt.pred_test <- predict(dt.fit, tree_test)
      
      dt.performance_test <- ifelse(dt.pred_test > 0.5, 1, 0)
      trainingSuccesful2 <- data.frame(trainPartition = tree_test$PCR, predict = dt.performance_test)

      lista <-  append(lista,calculo_de_Accuracy(trainingSuccesful2))
      lista <-  append(lista,as.numeric(dt.pred_test))
  
      resultados_decisionTrees[nrow(resultados_decisionTrees) + 1,] = lista
      lista <- list()
      i = i+1
      cp = cp+0.02    }
    plot(resultados_decisionTrees$areauc_train,resultados_decisionTrees$control)
    scatterplot3d(resultados_decisionTrees$areauc_train,resultados_decisionTrees$control,resultados_decisionTrees$areauc_test)
    return(resultados_decisionTrees)
}

```

Realizo la llamada a la función anterior :

```{r dev = 'svg', warning = FALSE}

decisionTree_crossVal(data,50, cp)

```
