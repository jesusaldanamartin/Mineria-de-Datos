---
title: "Algoritmos de Aprendizaje Computacional"
author: "Jesús Aldana Martín"
date: '2022-05-09'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#CLASE LUNES 09/05/2022# 

Librerias necesarias para la actividad:
```{r dev = 'svg', warning = FALSE}
library(caret)
library(ggplot2)
library(lattice)
library(pROC) # Permite calcular el area bajo la curva.
library(nnet) # Ofrece funciones de R para el Multilayer Perceptron Network.
library(e1071)# Funciones para el algoritmo computacional Support Vector Machine.
library(rpart)# Funciones para el algoritmo computacional Decision Trees.
library(ROCR)
```


Al igual que para la actividad anterior, debemos de encargarnos de procesar los datos y eliminar aquellos que se hayan perdido, que Rstudio marca como Na.

```{r dev = 'svg', warning = FALSE}

datos <- read.table(file="datos_proporcionados.csv", sep=";", dec=",", header=T, stringsAsFactors = TRUE)
datos$REst[datos$REst == "I"] <- NA
datos$RPro[datos$RPro == "I"] <- NA
datos$Her2[datos$Her2 == "I"] <- NA
datos<- na.omit(datos) 
data <- datos[,-1] #Eliminamos la columna Muestra.

```

Función a la que haremos referencia siempre que nos sea necesario calcular el accuracy de un modelo. Esta función crea la matriz de confusión de los datos observados y predichos, para despues hallar la suma de los true positives y false negatives para realizar el cociente por el total de datos.
```{r}
calculo_de_Accuracy <- function(df){
    m_confusion <- table(df$trainPartition, df$predict)
  return (sum(diag(m_confusion))/length(df$predict))
}
```

### Multilayer Perceptron Network ###


FUNCTION nnet --> #Multilayer Perceptron Network for TEST

Multilayer artificial neural network es uno de los métodos que mas destacan una vez nos adentramos en los algoritmos de aprendizaje profundo. Un algoritmo ANN de multicapas totalmente conectado suelen incluir 3 capas más una oculta, normalmente el número de capas y el número de neuronas son parámetros variables, por lo que necesitaremos algún método predictivo como Cross-Validation para hallar una solución ideal. Para ajustar el entrenamiento se realiza por retropropagación (Backpropagation). 

Por lo general aunque depende de nuestro dataset, a mayor número de redes neuronales mejor procesamiento de datos, sin embargo cuanto más capas mayor sera el error de desvanecimiento del gradiente (vanishing gradient problems). Para ello necesitaremos algoritmos específicos que disminuyan al máximo el error.

```{r dev = 'svg', warning = FALSE}

index <- createDataPartition(data$PCR, p=.8, list=FALSE, times=1)
train <- data[index,]
test <- data[-index,]

#Termina o cuando llega al máximo de iteraciones o cuando ya no tiene más senido continuar...
nn.fit <- nnet(train$PCR ~ ., data = train, size=6, entropy=TRUE, maxit=1000, decay=5e-4)

nn.pred_test <- predict(nn.fit, data = test, type="raw")

performance_predict <- ifelse(nn.pred_test > 0.5, 1, 0)


truePositives <- sum(data$PCR[performance_predict==1]==1)
trueNegative <- sum(data$PCR[nn.pred_test==0]==0)
falsePositive <- sum(data$PCR[nn.pred_test==1]==0)
falseNegtive <- sum(data$PCR[nn.pred_test==0]==1)

accu_test <- (truePositives + trueNegative)/(truePositives + trueNegative + falsePositive + falseNegtive) #Accuracy
area_under_curve_test <- auc(train$PCR, nn.pred_test) #AUC


accu_test
area_under_curve_test 
```

FUNCTION nnet --> #Multilayer Perceptron Network for TRAINING
```{r dev = 'svg', warning = FALSE}

nn.fit2 <- nnet(train$PCR ~ ., data = train, size=6, entropy=TRUE, maxit=1000, decay=5e-4)

nn.pred_train <- predict(nn.fit2, data = train, type="raw")

performance_predict2 <- ifelse(nn.pred_train > 0.5, 1, 0)

truePositives2 <- sum(data$PCR[performance_predict2==1]==1)
trueNegative2 <- sum(data$PCR[nn.pred_train==0]==0)
falsePositive2 <- sum(data$PCR[nn.pred_train==1]==0)
falseNegtive2 <- sum(data$PCR[nn.pred_train==0]==1)

accu_train <- (truePositives2 + trueNegative2)/(truePositives2 + trueNegative2 + falsePositive2 + falseNegtive2) #Accuracy
area_under_curve_train <- auc(train$PCR, nn.pred_train) #AUC

accu_train
area_under_curve_train 

#AUC APARENTE = es el auc con todo el conjunto de datos
#Si el auc es muy bajo tenemos un posible sobreentrenamiento

```

RESULTS (TBD)
```{r dev = 'svg', warning = FALSE}

print('TEST')
accu_test
area_under_curve_test

print('TRAIN')
accu_train
area_under_curve_train

```
###CLASE MIÉRCOLES 11/05/2022###

```{r dev = 'svg', warning = FALSE}
  


neuralNetwork_crossVal <- function(data, NN, maxit) {
  
    resultados <- data.frame(
      
      accu_train = double(),
      areauc_train = double(),
      accu_test = double(),
      areauc_test = double()
    )
    tabla_resultados <- data.frame(
      
      NN = double(),
      Accuracy = double(),
      AUC_test = double(),
      AUC_train = double()
    )
    
  # ESTE DATA FRAME TIENE EN CADA FILA LA MEDIA DE LOS VALORES ANTERIORES.
    
    i <- 1
    x <- 1
    lista <- list()
    lista2 <- list()

    while(NN >= i){
      
      index <- createDataPartition(data$PCR, p=.8, list=FALSE, times=1)
      #index <- createFolds(data$PCR, k = i, list=FALSE)

      train_df <- data[index,]
      test_df <- data[-index,]
  
      cv_nn.fit <- nnet(PCR == 1 ~ ., data = train_df, size=i, entropy=TRUE, maxit=maxit, decay=5e-4)
    
      cv_nn.pred_train_df <- predict(cv_nn.fit, train_df, type = "raw")

      cv_performance_predict_train <- ifelse(cv_nn.pred_train_df > 0.5, 1, 0)
      trainingSuccesful <- data.frame(trainPartition = train_df$PCR, predict = cv_performance_predict_train)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful))
      lista <-  append(lista,auc(train_df$PCR, cv_nn.pred_train_df))

      # ----- TEST ----- #
      cv_nn.pred_test_df <- predict(cv_nn.fit, test_df, type="raw")

      cv_performance_predict_test <- ifelse(cv_nn.pred_test_df > 0.5, 1, 0)
    
      trainingSuccesful2 <- data.frame(trainPartition = test_df$PCR, predict = cv_performance_predict_test)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful2))
      lista <-  append(lista,auc(test_df$PCR, cv_nn.pred_test_df))

      resultados[nrow(resultados) + 1,] <- lista
    
      #lista2 <- append(lista2, i)
      #lista2 <- append(lista2, mean(resultados$accu_test))
      #lista2 <- append(lista2, mean(resultados$areauc_train))
      #lista2 <- append(lista2, mean(resultados$areauc_test))

      #tabla_resultados[nrow(tabla_resultados) + 1,] <- lista2

      
      lista <- list()
      #lista2 <- list()

      i = i+1
      
    }
    
    print(resultados)
    while(NN >= x){
      
      neuralNetwork_crossVal(data, 5, 1000)
      
      lista2 <- append(lista2, x)
      lista2 <- append(lista2, mean(resultados$accu_test))
      lista2 <- append(lista2, mean(resultados$areauc_train))
      lista2 <- append(lista2, mean(resultados$areauc_test))
    
      tabla_resultados[nrow(tabla_resultados) + 1,] <- lista2
    
      x = x+1
    
    }
    
    return(tabla_resultados)
  
}



```

```{r dev = 'svg', warning = FALSE}

neuralNetwork_crossVal(data, 6, 1000)




#for(x in 1:10){
  #neuralNetwork_crossVal(data, 10, x, 1000)
  #tabla_resultados <- data.frame(NN = x, Accuracy = accu_test, AUC_Train = areauc_train, AUC_Test = areauc_test)
 # }

#Representar en 3D con un eje nº de neuronas, en otro el auc y acc

#PAQUETE más reciente plot3D
# NN -> Neuron Network col1
# Accuracy  col2
# AUC TRAIN col3
# AUC TEST col4

```

     
###CLASE MIÉRCOLES 11/05/2022###

Support Vector Machines (SVM) 
```{r dev = 'svg', warning = FALSE}

supporVector_crossVal <- function(data, k, c, g) {
  
     resultados2 <- data.frame(
      
      accu_train = double(),
      areauc_train = double(),
      accu_test = double(),
      areauc_test = double()
    )
    
    i <- 1
    lista <- list()

    while(k >= i){
      
      index <- createDataPartition(data$PCR, p=.8, list=FALSE, times=1)
      #index <- createFolds(data$PCR, k = i, list=FALSE)

      train_df <- data[index,]
      test_df <- data[-index,]
  
      svm.fit <- svm(PCR ==1 ~ ., data = train_df, cost = c,type = "C-classification" ,gamma = g, probability = TRUE, kernel="radial")

      pred <- predict(svm.fit, train_df, probability = TRUE)
      
      svm.pred <- attr(pred,which="probabilities")[,"TRUE"]

      svm_performance_predict_train <- ifelse(svm.pred > 0.5, 1, 0)
      trainingSuccesful <- data.frame(trainPartition = train_df$PCR, predict = svm_performance_predict_train)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful))
      lista <-  append(lista,auc(train_df$PCR,  svm.pred))

      # ----- TEST ----- #
      pred2 <- predict(svm.fit, train_df, probability = TRUE)
      svm.pred2 <- attr(pred2,which="probabilities")[,"TRUE"]

      svm_performance_predict_test <- ifelse(svm.pred2 > 0.5, 1, 0)
    
      trainingSuccesful2 <- data.frame(trainPartition = test_df$PCR, predict = svm_performance_predict_test)
      
      lista <- append(lista, calculo_de_Accuracy(trainingSuccesful2))
      lista <-  append(lista,auc(test_df$PCR, svm.pred2))

      resultados2[nrow(resultados2) + 1,] <- lista
      lista <- list()
      i = i+1
    }
    return(resultados2)
  
}

```

```{r dev = 'svg', warning = FALSE}

supporVector_crossVal(data, 5, 1, 1)

```


### DECISION TREES ###
```{r dev = 'svg', warning = FALSE}

decisionTree_crossVal <- function(data, k) {
  
  
    resultados_decisionTrees <- data.frame(
      
      accu_train = double(),
      areauc_train = double(),
      accu_test = double(),
      areauc_test = double()
    )
    
    i <- 1
    lista <- list()
    
    while(k >= i){
      


      index <- createDataPartition(data$PCR, p=.8, list=FALSE, times=1)
      #index <- createFolds(df$PCR, k = k, list=FALSE)

      tree_train <- data[index,]
      tree_test <- data[-index,]
     
       #TRAIN  
      dt.fit <- rpart(PCR == 1 ~ ., data = tree_train)
      
      dt.pred_train <- predict(dt.fit, tree_train, type = "prob")
      
      dt.performance_train <- ifelse(dt.pred_train > 0.5, 1, 0)
      trainingSuccesful <- data.frame(trainPartition = tree_train$PCR, predict = dt.performance_train)

      lista <-  append(lista,dt_accu_train)
      lista <-  append(lista,0)
      #lista <-  append(lista,auc(tree_train$PCR, as.factor(dt.pred_train)))

      # TEST
      dt.fit2 <- rpart(PCR == 1 ~ ., data = tree_test)

      dt.pred_test <- predict(dt.fit2, tree_test)
      
      dt.performance_test <- ifelse(dt.pred_test > 0.5, 1, 0)
      trainingSuccesful <- data.frame(trainPartition = tree_test$PCR, predict = dt.performance_test)

      lista <-  append(lista,dt_accu_test)
      lista <-  append(lista,0)
  
      resultados_decisionTrees[nrow(resultados_decisionTrees) + 1,] = lista
      lista <- list()
      i = i+1
    }
    
    return(resultados_decisionTrees)
}

```


```{r dev = 'svg', warning = FALSE}

decisionTree_crossVal(data,5)

```


